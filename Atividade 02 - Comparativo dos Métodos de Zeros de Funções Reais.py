# -*- coding: utf-8 -*-
"""FELIPE RIOS - RelatorioCN_compartivo_metodos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kcOMBPdfAO_WzGk5Sy52VXtYdC6fHxdZ

# Atividade 02 - Zeros de Funções Reais

```
# Isto está formatado como código
```

Nome completo: Felipe Moreira Rios

Data: 30/04/25

Você deverá produzir um relatório contendo os seguintes tópicos:


1. Estudo do sinal da função e localização de um intervalo da reta real que contém uma raiz. Use o mesmo intervalo para todos os diferentes métodos. Deve-se considerar o cálculo de apenas 1 (uma) raiz, a sua escolha, mesmo que sua função possua várias raízes.

2. Descrição do método numérico contendo o código utilizado para se encontrar uma aproximação para a raiz com 4 casas decimais de precisão (erro <= 0,00009). Especificar o resultado e a quantidade de passos necessários para se chegar àquele resultado. Esta seção deverá ser composta por sub-seções onde cada sub-seção representa um método diferente. Deverá conter, portanto, 5 sub-seções.

3. Fazer uma comparação ente os métodos, informando qual é mais eficiente do ponto de vista computacional para a função que você trabalhou (compare o número de iterações entre cada método). Detalhar também as possíveis dificuldades encontradas e possíveis não convergência de algum dos métodos para a sua função.

FELIPE MOREIRA RIOS
f(x) = 2^x - x^2

# Introdução

O presente trabalho apresenta o relatório da implementação computacional de diferentes técnicas numéricas estudadas na disciplina de Cálculo Numérico, lecionada às turmas de engenharia da Unidade Acadêmica de Belo Jardim. Utiliza-se a linguagem Python para a implementação dos algoritmos e considera-se a função

$$f(x) = 2^x-x^2$$
"""

import math as m

# defina aqui a sua função

def f(x):
    return 2**x - x**2

"""# Estudo do sinal da função

A função $f(x) = 2 ^x−x^2$ possui pelo menos uma zero no intervalo $(a,b)$ uma vez que $f(1) = 1 $, $f(3) = -1$, de modo que a função troca de sinal no intervalo considerado.

Calulando-se a derivada da função obtem-se

$$f'(x) = 2^xln(2)−2x$$

Verifica-se que $f'(x)>0 \, (ou <0)$ para todo $x\in(a,b)$. Portanto, como a derivada não troca de sinal em $(a,b)$, existe um único zero para $f(x)$ neste intervalo.

O intervalo $(a,b)$ será utilizada para todos os métodos numéricos a serem implementados, a fim de comparação de eficiência entre os métodos.


"""

# defina o intervalo
a = 0
b = 3

"""Para todos os os métodos a serem implementados e comparados, será considerada a precisão $ɛ=0.00009$ de quatro casas decimais, como segue:"""

# precisão
e = 0.00009

#Plote o gráfico da função caso ache conveniente para a análise do sinal da função.
import numpy as np
import matplotlib.pyplot as plt

x_vals = np.linspace(a, b, 100)
y_vals = [f(x) for x in x_vals]

plt.plot(x_vals, y_vals, label=r'$f(x) = 2^x - x^2$', color='blue')
plt.axhline(0, color='black', linestyle='--')
plt.axvline(0, color='black', linestyle='--')
plt.title(r'Gráfico de $f(x) = 2^x - x^2$')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.grid(True)
plt.legend()
plt.show()

"""# Método da Bissecção

O método da bissecção baseia-se no teorema de Bolzano, que garante a existência de uma raiz em um intervalo quando a função é contínua e muda de sinal nos extremos do intervalo. O algoritmo divide repetidamente o intervalo pela metade até que o erro seja suficientemente pequeno.
"""

# Implemente aqui o algoritmo do método da bissecção usando a sua função, o intervalo (a,b) e a precisão considera.
# Obtenha sempre o número de iterações necessárias à convergência a fim de comparação entre os métodos.

def bisseccao(f, a, b, e, max_iter=100):
    fa, fb = f(a), f(b)
    if fa * fb >= 0:
        return None, 0  # Não existe raiz no intervalo

    iteracoes = 0
    while (b - a) / 2 > e and iteracoes < max_iter:
        iteracoes += 1
        c = (a + b) / 2
        fc = f(c)
        print(f"Iteração {iteracoes:3d}: a = {a:.6f}, b = {b:.6f}, c = {c:.6f}, f(c) = {fc:.6e}")
        if abs(fc) < e:
            return c, iteracoes
        if fa * fc < 0:
            b, fb = c, fc
        else:
            a, fa = c, fc

    if iteracoes >= max_iter:
        print(f"Máximo de {max_iter} iterações atingido sem convergência completa.")
    return (a + b) / 2, iteracoes

raiz, passos = bisseccao(f, a, b, e)
print(f"\nRaiz aproximada: {raiz:.6f} em {passos} iterações")

"""# Método da Posição Falsa

O método da posição falsa é semelhante ao da bissecção, mas utiliza uma aproximação linear para encontrar um ponto intermediário. Em vez de dividir o intervalo ao meio, ele usa uma interceptação linear.
"""

# Implemente aqui o algoritmo do método da posição usando a sua função, o intervalo (a,b) incial e a precisão considera.
# Obtenha sempre o número de iterações necessárias à convergência a fim de comparação entre os métodos.

import math

def f(x):
    return 2**x - x**2

def posicao_falsa(f, a, b, e, max_iter=100):
    fa, fb = f(a), f(b)
    if fa * fb >= 0:
        return None, 0  # Não garante raiz nesse intervalo

    iteracoes = 0
    while (b - a) > e and iteracoes < max_iter:
        iteracoes += 1
        c = b - fb * (b - a) / (fb - fa)  # Fórmula da Posição Falsa
        fc = f(c)
        print(f"Iteração {iteracoes:3d}: a = {a:.6f}, b = {b:.6f}, c = {c:.6f}, f(c) = {fc:.6e}")
        if abs(fc) < e:
            return c, iteracoes
        if fa * fc < 0:
            b, fb = c, fc
        else:
            a, fa = c, fc

    if iteracoes >= max_iter:
        print(f"Máximo de {max_iter} iterações atingido sem convergência completa.")
    return c, iteracoes

# Execução
raiz_pf, it_pf = posicao_falsa(f, a, b, e)
print(f"\nRaiz da Posição Falsa: {raiz_pf:.6f} em {it_pf} iterações")

"""# Método do Ponto Fixo

O método do ponto fixo consiste em transformar a equação  
$$
f(x)=0
$$  
em  
$$
x = \phi(x)
$$  
e, a partir de uma aproximação inicial $x_0\in(a,b)$, iterar  
$$
x_{k+1} = \phi(x_k)
$$  
até que  
$$
\lvert f(x_{k+1})\rvert < \varepsilon
$$  
onde $\varepsilon = 0{,}00009$.

Para garantir convergência, deve-se verificar que  
$$
\lvert \phi'(x)\rvert < 1
\quad\forall\,x\in(a,b),
$$  
e escolher $x_0$ dentro desse intervalo.

---

## Escolha de $\phi(x)$

Da equação  
$$
2^x - x^2 = 0
\;\Longrightarrow\;
x^2 = 2^x
\;\Longrightarrow\;
x = \sqrt{2^x},
$$  
definimos  
$$
\phi(x) = \sqrt{2^x}.
$$

Calculamos a derivada:  
$$
\phi'(x)
= \frac{d}{dx}\bigl(2^{x/2}\bigr)
= 2^{x/2}\,\frac{\ln2}{2}
= \frac{\ln2}{2}\,\sqrt{2^x}.
$$

No intervalo $[0,3]$, o máximo de $\lvert\phi'(x)\rvert$ ocorre em $x=3$:  
$$
\lvert\phi'(3)\rvert
= \frac{\ln2}{2}\,2^{3/2}
\approx 0{,}9803 < 1.
$$  
Portanto, $phi$ é contratante e o método converge.

Adota-se  
$$
x_0 = \frac{a+b}{2} = 1{,}5.
$$
"""

# Implemente aqui o algoritmo do método do ponto fixo usando a sua função,
# tomando uma condição inicial no intervalo (a,b) inicial, use a média do intervalo, e a precisão considera.
# Obtenha sempre o número de iterações necessárias à convergência a fim de comparação entre os métodos.
# Escolhemos phi(x) = sqrt(2^x), que satisfaz x = phi(x) <=> f(x)=0
import math

def phi(x):
    return math.sqrt(2**x)

def ponto_fixo(f, phi, a, b, e, max_iter=100):
    x0 = (a + b) / 2
    for k in range(1, max_iter+1):
        x1 = phi(x0)
        print(f"Iteração {k:2d}: x_k = {x0:.6f}, x_(k+1) = {x1:.6f}, f(x_(k+1)) = {f(x1):.6e}")
        #critério de parada duplo- mudança pequena e f(x) quase zero
        if abs(x1 - x0) < e and abs(f(x1)) < e:
            return x1, k
        x0 = x1
    raise RuntimeError(f"Não convergiu em {max_iter} iterações")

raiz_pf, it_pf = ponto_fixo(f, phi, a, b, e)
print(f"\nRaiz do Ponto Fixo: {raiz_pf:.6f} em {it_pf} iterações")

"""# Método de Newton

O método de Newton é um caso especial do método do ponto fixo que consiste em usar a função de iteração:

$$
\phi(x_k) = x_k - \dfrac{f(x_k)}{f'(x_k)}
$$

Este método é convergente se $f'(x) \neq 0$ e $f''(x)$ existir e for contínua em $(a,b)$. Verificando, obsevamos que

$$
f'(x) = 2^x \ln(2) - 2x
$$

Além disso,

$$
f''(x) = 2^x (\ln(2))^2 - 2
$$

"""

# Implemente aqui o algoritmo do método de Newton usando a sua função,
# tomando uma condição inicial no intervalo (a,b) inicial, use a média do intervalo, e a precisão considera.
# Obtenha sempre o número de iterações necessárias à convergência a fim de comparação entre os métodos.

def df(x):
    return m.log(2) * 2**x - 2 * x  # Derivada de f(x)

def newton(f, df, x0, e, max_iter=100):
    iteracoes = 0
    while iteracoes < max_iter:
        iteracoes += 1
        x1 = x0 - f(x0) / df(x0)
        print(f"Iteração {iteracoes:3d}: x_k = {x0:.6f}, x_(k+1) = {x1:.6f}, f(x_(k+1)) = {f(x1):.6e}")
        if abs(f(x1)) < e:
            return x1, iteracoes
        x0 = x1

    # se passar de max_iter sem parar
    print(f"Máximo de {max_iter} iterações atingido sem convergência completa.")
    return x0, iteracoes

x0 = (a + b) / 2

raiz_newton, it_newton = newton(f, df, x0, e)
print(f"\nRaiz de Newton: {raiz_newton:.6f} em {it_newton} iterações")

"""# Método da Secante

O método da secante é uma discretização do método de Newton, que, em vez de usar a derivada da função \( f(x) \), utiliza uma aproximação da tangente à curva da função através de dois pontos consecutivos. Esse método é útil para resolver equações de forma iterativa sem a necessidade de calcular derivadas.

Desta forma, as iterações são calculadas por:

$$
x_{k+1} = \dfrac{x_{k-1} \cdot f(x_k) - x_k \cdot f(x_{k-1})}{f(x_k) - f(x_{k-1})}
$$

onde:

- $ x_k $ e $ x_{k-1} $ são os dois pontos mais recentes.
- $ f(x_k) $ e $ f(x_{k-1}) $ são os valores da função $f(x)$ nos pontos $ x_k $ e $ x_{k-1} $.

Assim, são necessárias duas condições iniciais $ x_0 $ e $ x_1 $ no
intervalo $ (0, 3) $, onde a função muda de sinal, e essas condições iniciais são utilizadas para iniciar o processo iterativo. A cada iteração, o próximo ponto $ x_{k+1} $ é calculado, e o processo continua até que o valor da função em $ x_{k+1} $ seja suficientemente pequeno ou a diferença entre os pontos sucessivos seja menor que a precisão desejada.

"""

# Implemente aqui o algoritmo do método da secante usando a sua função,
# tomando duas condições iniciais no intervalo (a,b) inicial, e a precisão considera.
# Obtenha sempre o número de iterações necessárias à convergência a fim de comparação entre os métodos.
def secante(f, x0, x1, e, max_iter=100):
    iteracoes = 0
    while iteracoes < max_iter:
        iteracoes += 1
        fx0, fx1 = f(x0), f(x1)
        x2 = x1 - fx1 * (x1 - x0) / (fx1 - fx0)
        print(f"Iteração {iteracoes:3d}: x_(k-1) = {x0:.6f}, x_k = {x1:.6f}, x_(k+1) = {x2:.6f}, f(x_(k+1)) = {f(x2):.6e}")
        if abs(f(x2)) < e:
            return x2, iteracoes
        x0, x1 = x1, x2

    print(f"Máximo de {max_iter} iterações atingido sem convergência completa.")
    return x2, iteracoes

raiz_secante, it_secante = secante(f, a, b, e)
print(f"\nRaiz da Secante: {raiz_secante:.6f} em {it_secante} iterações")

# ——— Chamadas dos métodos ———
raiz_bisseccao, it_bisseccao           = bisseccao(f, a, b, e)
raiz_posicao_falsa, it_posicao_falsa   = posicao_falsa(f, a, b, e)
raiz_ponto_fixo, it_ponto_fixo         = ponto_fixo(f, phi, a, b, e)
x0                                      = (a + b) / 2
raiz_newton, it_newton                 = newton(f, df, x0, e)
raiz_secante, it_secante               = secante(f, a, b, e)

# ——— Resultados das Raízes e Número de Iterações ———
print("\nResultados das Raízes e Número de Iterações:")
print(f"Bissecção:     Raiz = {raiz_bisseccao:.6f}, Iterações = {it_bisseccao}")
print(f"Posição Falsa: Raiz = {raiz_posicao_falsa:.6f}, Iterações = {it_posicao_falsa}")
print(f"Ponto Fixo:    Raiz = {raiz_ponto_fixo:.6f}, Iterações = {it_ponto_fixo}")
print(f"Newton:        Raiz = {raiz_newton:.6f}, Iterações = {it_newton}")
print(f"Secante:       Raiz = {raiz_secante:.6f}, Iterações = {it_secante}")

"""# Resultados e Discussões

Dentre os resultados obtidos, verificou‐se que o Método de Newton apresentou melhor eficiência com base no número de iterações, conforme mostra a tabela a seguir:

<table>
  <thead>
    <tr>
      <th>Método</th>
      <th>Raiz</th>
      <th>Número de Iterações</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Bissecção</td>
      <td>2.000061</td>
      <td>14</td>
    </tr>
    <tr>
      <td>Posição Falsa</td>
      <td>1.999997</td>
      <td>4</td>
    </tr>
    <tr>
      <td>Ponto Fixo</td>
      <td>1.999941</td>
      <td>24</td>
    </tr>
    <tr>
      <td>Método de Newton</td>
      <td>2.000035</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Método da Secante</td>
      <td>1.999997</td>
      <td>4</td>
    </tr>
  </tbody>
</table>

- **Método de Newton** foi o mais eficiente, com apenas $2$ iterações, o que evidencia sua convergência quadrática e o uso da derivada para acelerar a aproximação.  
- **Método da Posição Falsa** e **Método da Secante** empataram, cada um com $4$ iterações, aproveitando aproximações lineares para localizar rapidamente a raiz.  
- **Método da Bissecção**, embora robusto e garantido, levou $14$ iterações, refletindo seu processo de divisão sistemática do intervalo.  
- **Método do Ponto Fixo** foi o mais lento, com $24$ iterações, demonstrando a sensibilidade à escolha de $\phi(x)$ e a convergência geralmente mais lenta desse método.

### Dificuldades e Análises

- **Ponto Fixo**: exigiu $24$ iterações devido à convergência gradual; poderia ser otimizado com outra forma de $\phi(x)$.  
- **Bissecção**: não apresentou dificuldades, mas é inevitavelmente mais lento diante de alta precisão.  
- **Newton**: convergiu em $2$ iterações; requer cuidado se $f'(x)\approx 0$, pois pode divergir.  
- **Posição Falsa / Secante**: bons resultados com poucos passos, mas podem ficar instáveis se $f(a)$ e $f(b)$ forem muito próximos em magnitude.

Em conclusão, a escolha do método deve equilibrar garantia de convergência (Bissecção), simplicidade (Ponto Fixo) e velocidade (Newton e Secante).

"""

#Newton code prof
def f_linha(X):
  return np.log()

#copia parte do ponto fixo
x0
x_k

it max
for k in range(1, it)
  x_k = x_k - f(x_k)/ f_linha(x_k)

if abs(f(x_k)) < e:
  break

print('solução' x_k)
print('iterações' k)

#Secante code prof
#Newton code prof
def f_linha(X):
  return np.log()

#copia parte do ponto fixo
x0=
x1=

it max =
for k in range(1, it_max_secante)
  print(x2)
  x2 = (x0 * f(x1) - x1 * f(x0)) / (f(x1)-f(x0)
  x0 = x1
  x1 = x2

if abs(f(x2)) < e:
  break

print('solução' x_k)
print('iterações' k)